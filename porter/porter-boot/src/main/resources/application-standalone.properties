#日志等级
logging.level.root=info

#端口
server.port=9002

#节点描述
#porter.id=10000

#开启自动gc控制(4.0新增)
porter.gc=true

#项目前缀路径
#server.servlet.context-path=/api

#zk集群配置
#porter.cluster.strategy=ZOOKEEPER
#porter.cluster.client.url=127.0.0.1:2181,127.0.0.2:2181,127.0.0.3:2181
#porter.cluster.client.sessionTimeout=100000

#数据收集开关
porter.statistic.upload=true
#使用kafka统计数据
#porter.cluster.statistic.sourceType=KAFKA_PRODUCE
#porter.cluster.statistic.servers=127.0.0.1:9092,127.0.0.2:9092
#porter.cluster.statistic.topic=porter_event


#单机模式
porter.cluster.strategy=STANDALONE
porter.cluster.client.home=./.porter

#会加载tasks/sample文件夹下的任务配置(2.0任务配置方案)
#spring.profiles.active=sample


#详细日志等级控制
logging.level.com.alibaba.druid.pool.DruidDataSource=INFO
#logging.level.org.apache.kafka=INFO
#logging.level.org.apache.zookeeper=INFO
#logging.level.org.apache.commons.beanutils=INFO
#logging.level.org.springframework=INFO
#logging.level.org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator=DEBUG


#日志位置
logging.file=${app.home}/logs/data-node.log
